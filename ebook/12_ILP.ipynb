{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faaefe4f-645a-46d3-89f8-93dba9cf3d7a",
   "metadata": {},
   "source": [
    "## Instruction-Level Parallelism and Vectorization\n",
    "\n",
    "Instruction-Level Parallelism (ILP) refers to the parallel execution of a sequence of instructions in a program. The amount of parallelism is measured by the number of instructions completed per cycle. ILP is not concurrent execution, because there is only a single-thread serial program. Rather, it is a set of techniques that are used to ensure that a processor completes as many instructions as possible by executing them simultaneously.  These techniques include:\n",
    "\n",
    "* Instruction pipelining: instructions are completed in stages that can be overlapped when instructions are independent.\n",
    "\n",
    "* Vector processing: multiple instructions can be executed in parallel on adjacent data.  This is a subset of superscalar processing, which is a more general term that includes the idea of using different hardware units at the same time. \n",
    "\n",
    "* Out-of-order execution: Instructions may be run in an order different than written in the program. This can be done statically at compile time or dynamically by the hardware.\n",
    "\n",
    "* Speculative execution (branch prediction): Running a program past a control point. Most often this is done by predicting the outcome of an if-else branch and running the program past the expected outcome. \n",
    "\n",
    "\n",
    "One should be aware that all of these techniques exist and have a high-level understanding of them. As a parallel programmer, only **vector processing** has a programmatic interface that you will use.\n",
    "\n",
    "It is typical to assume that CPUs complete one instruction per cycle. This is *NOT TRUE*. The completion rate is a complex function of architecture and program.\n",
    "This is measured by:\n",
    "* Cycles per instruction (CPI): # of clock cycles / # of instructions\n",
    "* Instructions per cycles (IPC): # of instructions / # of clock cycles\n",
    "\n",
    "These are dynamic measures taking against a running program. It is more typical to use CPI in parallel computing, because we are expecting to complete more than one.  \n",
    "\n",
    "If you would like to go down the well, you can look at the [instruction tables](https://www.agner.org/optimize/instruction_tables.pdf) at the [Software optimization resources](https://www.agner.org/optimize/) page.\n",
    "On many processers, the simplest instructions take about one cycle and complex instructions (such as division) take tens of cycles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b8034-8b9b-46b7-bf0d-48c655d30b84",
   "metadata": {},
   "source": [
    "### Instruction Pipelining\n",
    "\n",
    "Having a high-level knowledge of instruction pipeling is valuable in writing efficient code, be it parallel or not. The illustrated example of the [Wikipedia page](https://en.wikipedia.org/wiki/Instruction_pipelining) and the subsequent pipeline bubble example are sufficient. You should understand the following concepts:\n",
    "* Instructions consist of multiple stages of execution\n",
    "* Each stage can operate at the same time\n",
    "* Independent instructions are issued and complete at a rate of one per clock cycle\n",
    "* Data dependencies between instructions result in stalls/bubbles that prevent concurrent execution\n",
    "* Waiting on instructions or data (often from memory) can prevent instructions from being issued\n",
    "\n",
    "Managing the pipeline is the domain of the compiler writer or assembly-level programmer. However, an application programmer that is aware of pipelines can write programs that are easier for the compiler to process by minimizing data dependencies, avoiding unneccessary branches, or explicitly prefetching data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e43284-bb1a-4c2a-be47-2bbad60be108",
   "metadata": {},
   "source": [
    "### Vector Processing\n",
    "\n",
    "A _vector processor_ is a CPU that is designed to perform simulatneous instructions on a one-dimensional array (vector) of data. The design space of vector processors is rich and varied. We will consider a limited subset of vector operations called _Single Instruction Stream, Multiple Data Stream_ (SIMD) vectors of fixed width. This is called Pure (fixed) SIMD or Packed SIMD. The Graphics Processing Units (GPUs) that drive modern AI hardware are another example of a vector processor that operate on very-wide vectors.\n",
    "\n",
    "Our examples will use the Intel instrinsic functions to program 128-bit vectors to demonstrate the speedup possible from parallel execution in the SIMD model.\n",
    "\n",
    "#### What is a vector?\n",
    "\n",
    "A vector is a packed array of data elements that vary from 8-64 bits into a 128-512 bit contiguous region of memory. Operations against vectors conduct a basic operation (add, multiply) against all elements of the vector simultaneously.   \n",
    "\n",
    "![Vector Operation](./images/vector_op.JPG \"Vector Operation\")\n",
    "\n",
    "Compilers provides _intrinsic_ functions that allow one to call vector instructions using C-style functions. They are much more convenient than writing assembly code.\n",
    "\n",
    "#### What about my compiler?\n",
    "\n",
    "For the most part, compilers do a reasonable job of vectorizing code, particulary code in loops. However, the suitability of code for vectorization depends upon how it is written.  If you write code that is conducting the same operation on a sequential array of data then the compiler will vectorize the code. If you write semantically equivalent code that does not access data sequentially then the compiler will be unable to vectorize it.  \n",
    "\n",
    "__Conclusion__: You can rely on your compiler to automatically vectorize your code when you write it in a way that it can be vectorized. To do so, you must understand vectorization.\n",
    "\n",
    "There are cases in which the compiler won't do a good job and you will need to vectorize your code by hand. To determine this, you will need to inspect the compiler generated code. Again, you need to understand vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bd627-b4e9-4d53-893f-2d66c7299c6a",
   "metadata": {},
   "source": [
    "### Interpreting Code with Compiler Explorer\n",
    "\n",
    "Given an array of data, we want to count how many ints are equal to the target.\n",
    "\n",
    "Here is some simple code to count.\n",
    "```c\n",
    "long count_ints(int* data, long n, int target) {\n",
    "    long count = 0;\n",
    "    for (long i = 0; i < n; i++) {\n",
    "        if (data[i] == target) {\n",
    "            count+=1;\n",
    "        }\n",
    "    }\n",
    "    return count;\n",
    "}\n",
    "```\n",
    "\n",
    "To help us look at code and how it compiles we are going [Compiler Explorer](https://godbolt.org/). This website allows you to, among other things, compile code online and view the assembly. The specific problem we are looking at is We can see it https://godbolt.org/z/sdn6nx9Ph. Compiling with `-O3 -mno-sse -fno-unroll-loops ` produces the following:\n",
    "\n",
    "```\n",
    "count_ints(int*, long, int):\n",
    "        test    rsi, rsi\n",
    "        jle     .LBB0_1\n",
    "        xor     ecx, ecx\n",
    "        xor     eax, eax\n",
    ".LBB0_4:\n",
    "        xor     r8d, r8d\n",
    "        cmp     dword ptr [rdi + 4*rcx], edx\n",
    "        sete    r8b\n",
    "        add     rax, r8\n",
    "        inc     rcx\n",
    "        cmp     rsi, rcx\n",
    "        jne     .LBB0_4\n",
    "        ret\n",
    ".LBB0_1:\n",
    "        xor     eax, eax\n",
    "        ret\n",
    "```\n",
    "\n",
    "If we ask ChatGPT to help us read the core code:\n",
    "\n",
    "```\n",
    ".LBB0_4:\n",
    "    xor     r8d, r8d                       ; Clear R8D (temporary storage for match flag)\n",
    "    cmp     dword ptr [rdi + 4*rcx], edx   ; Compare array[i] with target\n",
    "    sete    r8b                            ; Set R8B to 1 if equal, else 0\n",
    "    add     rax, r8                        ; Add R8 to EAX (increment count if match)\n",
    "    inc     rcx                            ; Increment loop counter\n",
    "    cmp     rsi, rcx                       ; Compare loop counter with length\n",
    "    jne     .LBB0_4                        ; If not equal, continue loop\n",
    "    ret                                    ; Return the count\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011e9b9-cc42-4f49-b7cb-a22cdd322555",
   "metadata": {},
   "source": [
    "Compiling the same code with `-O3 -mavx2 -fno-unroll-loops` uses the AVX extensions to the Intel archiecture for 128-bit vectors. This core code (after some complex setup).\n",
    "\n",
    "\n",
    "```\n",
    ".LBB0_6:\n",
    "        vpcmpeqd   xmm3, xmm1, xmmword ptr [rdi + 4*rax]  ; Compare four integers with 'target'\n",
    "        vpmovzxdq  ymm3, xmm3                             ; Zero-extend comparison results\n",
    "        vpand   ymm3, ymm3, ymm2                          ; Mask comparison results with '1'\n",
    "        vpaddq  ymm0, ymm0, ymm3                          ; Accumulate counts\n",
    "        add     rax, 4                                    ; Move to the next block of four\n",
    "        cmp     rcx, rax                                  ; Check if all blocks are processed\n",
    "        jne     .LBB0_6                                   ; If not, continue the loop\n",
    "\n",
    "```\n",
    "\n",
    "The main instruction here is `vpcmpqeqd` which has pseudocode:\n",
    "```\n",
    "FOR j := 0 to 3\n",
    "\ti := j*32\n",
    "\tdst[i+31:i] := ( a[i+31:i] == b[i+31:i] ) ? 0xFFFFFFFF : 0\n",
    "ENDFOR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf913bf-22ca-4ac4-bf99-0078591e3994",
   "metadata": {},
   "source": [
    "### Intrinsics\n",
    "\n",
    "If you want to program to vectors manually and you don't want to write assembly code, you can use function call wrappers to vector instructions.  These are known as [intrinsics](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html) \n",
    "that compile down to a single assembly instruction \n",
    "\n",
    "For example to call [vpcmpeqd](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_cmpeq_epi32&ig_expand=878,879) and compare 8 32-bit integers at once we can use \n",
    "\n",
    "`__m256i _mm256_cmpeq_epi32 (__m256i a, __m256i b)`\n",
    "\n",
    "We are going to compare 8 elements at a time.  This means our main loop with increment by 8 each time.  This means we will also have to perform work at the end to deal with any extra iterations. The code must also initialize the \n",
    "\n",
    "```c\n",
    "\n",
    "long count_ints(int* data, long n, int target) {\n",
    "  long count = 0;\n",
    "  long clean_end = (n / 8) * 8;\n",
    "  long i = 0;\n",
    "  for (; i < clean_end; i += 8) {\n",
    "      auto cmp_vec = _mm256_cmpeq_epi32(\n",
    "        _mm256_loadu_si256((__m256i *)(data + i)),\n",
    "                                    _mm256_set1_epi32(target));\n",
    "        int movemask = _mm256_movemask_epi8(cmp_vec);\n",
    "        count += _mm_popcnt_u32(movemask);\n",
    "  }\n",
    "  // we need this division to handle the fact we pulled out the bytes not the ints, but we can pull it out of the loop\n",
    "  count /=4;\n",
    "  for (; i < n; i++) {\n",
    "    if (data[i] == target) {\n",
    "      count += 1;\n",
    "    }\n",
    "  }\n",
    "  return count;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "I don't expect you to full understand this example. I do want you to know that intrinsics exist.\n",
    "This code and the assembly can be seen [https://godbolt.org/z/zdaac8fsT](https://godbolt.org/z/zdaac8fsT).\n",
    "\n",
    "The downside of intrinsics is that they are compiled for a particular archictecture. In practice, code that relies on intrinsics will have a base (non-optimized) implementation available when the hardware does not have the optimized instruction. \n",
    "\n",
    "Compilers are more portable and should generate vectorized code when it's possible. This is what happened in the matrix multiplication example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffc1d7-f909-4273-9863-c066bda61825",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "* Vector instructions are critical to realize high CPI.\n",
    "* Your compiler can help you:\n",
    "    * but you should check it's work\n",
    "* You can use intrinsics if your compiler is not accomplishing your goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159edc0-3fd5-4829-82c7-81c4f1603e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
